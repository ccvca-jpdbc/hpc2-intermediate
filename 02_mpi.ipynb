{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d79f77f-367c-42f6-a5d8-211905457de1",
   "metadata": {},
   "source": [
    "### **Fundamentos de MPI: Modelos, Tipos de Comunicação e Implementações**\n",
    "\n",
    "## 1. Modelos de paralelismo em MPI\n",
    "\n",
    "Em MPI (Message Passing Interface), um programa paralelo é composto por múltiplos processos independentes, cada um identificado por um número (rank). Estes processos executam o mesmo programa e comunicam entre si trocando mensagens.\n",
    "Existem dois grandes modelos de paralelismo:\n",
    "\n",
    "**1.1. Decomposição espacial**\n",
    "\n",
    "A decomposição espacial divide o espaço de dados entre os processos.\n",
    "Cada processo executa o mesmo código, mas sobre uma parte distinta dos dados.\n",
    "Este modelo é adequado quando os dados são naturalmente separáveis, como linhas de uma imagem, blocos de uma matriz ou conjuntos de ficheiros.\n",
    "\n",
    "**Exemplo:**\n",
    "Num livro de vários capítulos, várias pessoas podem contar as palavras em paralelo — cada pessoa lê um capítulo diferente. No final, os resultados são somados.\n",
    "Em MPI, cada processo seria responsável pelo seu “capítulo” de dados, e o processo principal recolheria os resultados globais.\n",
    "\n",
    "**Dependência entre partes dos dados:**\n",
    "Em alguns casos, os cálculos de uma parte dependem de valores adjacentes que pertencem a outra parte.\n",
    "Isto acontece, por exemplo, quando se aplica um filtro de média móvel ou uma convolução.\n",
    "\n",
    "**Exemplo prático:**\n",
    "Para calcular a média de três pontos de um vetor (x[i-1], x[i], x[i+1]), o processo que detém o último valor do primeiro bloco precisa de x[i+1], pertencente ao processo seguinte.\n",
    "Neste caso, é necessário trocar linhas ou colunas de fronteira entre processos — as chamadas linhas de halo.\n",
    "Este mecanismo chama-se halo exchange e permite que os processos vizinhos partilhem apenas a informação mínima indispensável.\n",
    "\n",
    "**Vantagens:** grande escalabilidade e simplicidade conceptual.\n",
    "**Desafio:** exige comunicação adicional nas fronteiras entre blocos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92f4b0-82b9-4e2c-a97b-c119f95e9371",
   "metadata": {},
   "source": [
    "**1.2. Decomposição temporal**\n",
    "\n",
    "A decomposição temporal divide o processamento em etapas sucessivas.\n",
    "Cada processo representa uma fase distinta de um fluxo de execução, formando uma cadeia (ou pipeline).\n",
    "\n",
    "**Exemplo:**\n",
    "Numa linha de produção, o primeiro trabalhador corta o material, o segundo pinta e o terceiro embala.\n",
    "Em MPI, o primeiro processo gera dados, o segundo processa e o terceiro grava resultados.\n",
    "\n",
    "**Vantagens:** útil quando há dependência lógica entre fases que podem sobrepor-se no tempo.\n",
    "**Desafio:** se uma fase for muito mais lenta, torna-se um gargalo e reduz o paralelismo global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be350650-c65c-479c-9be2-ed31a54fff29",
   "metadata": {},
   "source": [
    "## 2. Tipos de comunicação em MPI\n",
    "\n",
    "MPI disponibiliza diferentes mecanismos de comunicação, adequados a cada modelo de paralelismo.\n",
    "\n",
    "**2.1. Comunicação ponto-a-ponto**\n",
    "\n",
    "Cada operação de comunicação ponto-a-ponto envolve um emissor e um recetor específicos.\n",
    "Embora cada par seja independente, vários pares podem comunicar em simultâneo dentro do mesmo programa.\n",
    "\n",
    "**Principais comandos:**\n",
    "\n",
    "Send() – envia dados e aguarda a conclusão do envio.\n",
    "\n",
    "Recv() – espera até receber dados.\n",
    "\n",
    "Isend() – inicia o envio, mas o processo pode continuar a executar.\n",
    "\n",
    "Irecv() – inicia a receção, permitindo continuar outras operações enquanto os dados chegam.\n",
    "\n",
    "Wait() – confirma que uma operação não bloqueante terminou.\n",
    "\n",
    "**Analogia:**\n",
    "Enviar e ler cartas.\n",
    "No envio bloqueante (Send/Recv), o remetente espera que o destinatário abra a carta.\n",
    "No envio não bloqueante (Isend/Irecv), o remetente coloca a carta no correio e continua a trabalhar; mais tarde confirma que foi entregue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77952815-535d-4226-b457-d02e47b9329c",
   "metadata": {},
   "source": [
    "**2.2. Comunicação coletiva**\n",
    "\n",
    "As comunicações coletivas envolvem todos os processos de um grupo e são coordenadas automaticamente pela biblioteca MPI.\n",
    "\n",
    "**Principais comandos:**\n",
    "\n",
    "Bcast() – envia o mesmo valor a todos os processos.\n",
    "\n",
    "Scatter() – divide um conjunto de dados e distribui partes diferentes.\n",
    "\n",
    "Gather() – recolhe resultados de todos e junta-os num só processo.\n",
    "\n",
    "Reduce() – combina valores de todos os processos (por soma, média, máximo, etc.).\n",
    "\n",
    "Barrier() – força todos os processos a esperar no mesmo ponto antes de continuar.\n",
    "\n",
    "**Exemplo de Reduce:**\n",
    "Se cada processo calcula o número de palavras no seu bloco e se utiliza Reduce com MPI.SUM, o MPI soma automaticamente todos os resultados e entrega a soma total ao processo principal (root).\n",
    "Se se pretender calcular a média, soma-se primeiro com MPI.SUM e depois divide-se o resultado total pelo número de processos (size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b31c8f-48d7-4bac-88d8-2501adcc297d",
   "metadata": {},
   "source": [
    "**2.3. Comunicação com vizinhança (halo exchange)**\n",
    "\n",
    "Usada quando os dados estão organizados num domínio contínuo (imagem, matriz, grelha) e cada parte depende das fronteiras da parte vizinha.\n",
    "\n",
    "Funcionamento:\n",
    "\n",
    ">Cada processo processa o seu bloco principal.\n",
    "\n",
    ">Antes de cada iteração, envia as linhas ou colunas de fronteira para os vizinhos e recebe as correspondentes linhas de halo.\n",
    "\n",
    ">Enquanto as mensagens circulam, calcula o interior do bloco.\n",
    "\n",
    ">Quando as mensagens chegam, calcula as fronteiras com base nos halos recebidos.\n",
    "\n",
    "**Analogia:**\n",
    "Várias pessoas pintam uma parede dividida em quadrados.\n",
    "Para que as cores coincidam nas bordas, cada pessoa mostra uma pequena faixa da sua pintura ao vizinho antes de continuar.\n",
    "\n",
    "O halo exchange é normalmente implementado com Isend() e Irecv() para permitir que o cálculo do interior decorra em simultâneo com a transferência dos halos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db2df1-f753-4702-980c-1d3137045939",
   "metadata": {},
   "source": [
    "## 3. Comunicação bloqueante e não bloqueante\n",
    "\n",
    "**3.1. Bloqueante (Send, Recv)**\n",
    "\n",
    "O processo espera que a operação termine antes de continuar.\n",
    "\n",
    "Porquê usar:\n",
    "É simples e garante ordem previsível das trocas.\n",
    "\n",
    "Problemas possíveis:\n",
    "\n",
    "Espera ociosa: o emissor fica parado até o recetor estar pronto.\n",
    "\n",
    "Deadlock: dois processos podem ficar presos se ambos fizerem Send antes de qualquer Recv.\n",
    "\n",
    "Como evitar:\n",
    "\n",
    "Definir uma ordem fixa (por exemplo, pares enviam primeiro, ímpares recebem).\n",
    "\n",
    "Usar etiquetas (tags) para distinguir mensagens.\n",
    "\n",
    "Fazer as receções antes dos envios quando possível.\n",
    "\n",
    "Analogia:\n",
    "Entregar uma carta em mãos e esperar que o destinatário a leia antes de sair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f274a7-1403-4897-958e-6e3124d4fce2",
   "metadata": {},
   "source": [
    "**3.2. Não bloqueante (assíncrona) (Isend, Irecv, Wait)**\n",
    "\n",
    "O processo inicia a comunicação e continua a trabalhar enquanto a mensagem é transmitida.\n",
    "\n",
    "Porquê usar:\n",
    "Permite sobrepor comunicação e computação, melhorando o aproveitamento do tempo.\n",
    "É essencial em trocas de halos e pipelines.\n",
    "\n",
    "Problemas possíveis:\n",
    "\n",
    "Esquecimento de Wait: os dados podem não estar prontos quando usados.\n",
    "\n",
    "Alteração de buffers enquanto a mensagem ainda está a ser enviada.\n",
    "\n",
    "Como evitar:\n",
    "\n",
    "Usar Wait ou Waitall para garantir a conclusão das operações.\n",
    "\n",
    "Não modificar nem reutilizar os buffers de envio até a operação terminar.\n",
    "\n",
    "Analogia:\n",
    "Colocar uma carta no correio e continuar a trabalhar, confirmando mais tarde que foi entregue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0ea8f-dc6c-4598-86d6-463f86e21015",
   "metadata": {},
   "source": [
    "## 4. Gargalos (bottlenecks)\n",
    "\n",
    "Um gargalo ocorre quando um processo ou uma parte do programa concentra demasiado trabalho ou comunicação, limitando o desempenho global.\n",
    "\n",
    "Exemplo clássico:\n",
    "Num modelo master–worker, o processo principal (rank 0) distribui tarefas (Send) e recebe resultados (Recv) de todos os outros.\n",
    "Enquanto o mestre está ocupado a enviar e receber, os workers esperam.\n",
    "Este atraso chama-se gargalo de comunicação.\n",
    "\n",
    "Podem existir? Sim, algumas fases seriais são inevitáveis (por exemplo, leitura ou escrita única num ficheiro).\n",
    "Devem ser evitados? Devem ser minimizados, pois reduzem o ganho de velocidade (speedup).\n",
    "\n",
    "Como minimizar:\n",
    "\n",
    "Substituir trocas manuais por comunicações coletivas (Scatter, Gather, Reduce).\n",
    "\n",
    "Distribuir trabalho de forma equilibrada.\n",
    "\n",
    "Usar comunicações não bloqueantes (Isend, Irecv) para sobrepor transferência e cálculo.\n",
    "\n",
    "Dividir tarefas seriais por grupos ou fases paralelas sempre que possível.\n",
    "\n",
    "Analogia:\n",
    "Num restaurante, se apenas um empregado servir todas as mesas, o serviço atrasa. Se cada empregado servir uma zona, o trabalho flui em paralelo e o tempo de espera reduz-se."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851f30b-b2ca-49bd-ac2e-7e4a37b8e674",
   "metadata": {},
   "source": [
    "## 5. Principais comandos MPI e respetivo comportamento\n",
    "\n",
    "| Comando   | Tipo de comunicação           | Comportamento                                  | Exemplo                              |\n",
    "| --------- | ----------------------------- | ---------------------------------------------- | ------------------------------------ |\n",
    "| `Send`    | Ponto-a-ponto, bloqueante     | Envia dados e espera confirmação               | Enviar número do processo 0 para o 1 |\n",
    "| `Recv`    | Ponto-a-ponto, bloqueante     | Espera e recebe dados de outro processo        | Receber número enviado pelo 0        |\n",
    "| `Isend`   | Ponto-a-ponto, não bloqueante | Inicia envio e continua execução               | Enviar dados enquanto calcula        |\n",
    "| `Irecv`   | Ponto-a-ponto, não bloqueante | Inicia receção e prossegue execução            | Receber dados em fundo               |\n",
    "| `Wait`    | —                             | Aguarda fim de comunicação não bloqueante      | Confirmar entrega ou receção         |\n",
    "| `Barrier` | Coletiva                      | Todos esperam no mesmo ponto                   | Sincronizar início de uma nova fase  |\n",
    "| `Bcast`   | Coletiva                      | Envia o mesmo valor a todos                    | Difundir variável comum              |\n",
    "| `Scatter` | Coletiva                      | Distribui partes de um conjunto de dados       | Enviar subconjuntos a cada processo  |\n",
    "| `Gather`  | Coletiva                      | Recolhe resultados de todos                    | Juntar resultados num só processo    |\n",
    "| `Reduce`  | Coletiva                      | Combina resultados (soma, média, máximo, etc.) | Calcular soma total ou média global  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473f6c1-8b5d-49e0-9d27-81130d281ffe",
   "metadata": {},
   "source": [
    "## 6. Modelos, implementações e exemplos de código\n",
    "\n",
    "| Código / Exemplo                           | Modelo de paralelismo                       | Tipo de comunicação                                   | Padrão / implementação                    | Descrição                                                                                                                                                                                                                                                                      |\n",
    "| ------------------------------------------ | ------------------------------------------- | ----------------------------------------------------- | ----------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **ex1_hello_ordenado.py**                  | **Temporal**                                | **Coletiva (`Barrier`)**                              | **Sincronização por turnos**              | Cada processo imprime a sua mensagem apenas no seu turno, aguardando nos mesmos pontos de barreira que os restantes. Demonstra coordenação temporal e execução ordenada.                                                                                                       |\n",
    "| **ex2_broadcast_matriz.py**                | **Espacial (comum a todos)**                | **Coletiva (`Bcast`)**                                | **Difusão global**                        | O processo *root* cria uma matriz e envia cópias idênticas a todos os outros. Mostra a transmissão um-para-todos de um estado inicial comum.                                                                                                                                   |\n",
    "| **ex3_scatter_gather_linhas.py**           | **Espacial (distribuição por blocos)**      | **Coletivas (`Scatterv` / `Gatherv` / `Bcast`)**      | **Partição e recomposição**               | A matriz é dividida por linhas; cada processo trata o seu sub-bloco local, depois o *root* recompõe a matriz completa. Ilustra o padrão clássico de paralelismo de dados com partilha estruturada.                                                                             |\n",
    "| **ex4_reduce_soma_matrizes.py**            | **Espacial (redução global)**               | **Coletiva (`Reduce`)**                               | **Agregação de resultados**               | Cada processo cria uma matriz diferente; o *root* soma todas elemento-a-elemento. Mostra como combinar contributos locais num resultado único (soma ou média).                                                                                                                 |\n",
    "| **ex5_p2p_anel_sendrecv.py**               | **Espacial (topologia em anel)**            | **Ponto-a-ponto (`Sendrecv`)**                        | **Troca simétrica entre vizinhos**        | Cada processo envia o seu vetor ao vizinho seguinte e recebe do anterior. `Sendrecv` evita *deadlocks* porque o envio e a receção ocorrem num único passo sincronizado.                                                                                                        |\n",
    "| **ex6_allgather_blocos_pequenos.py**       | **Espacial (partilha total)**               | **Coletiva (`Allgather`)**                            | **Recolha global em todos**               | Cada processo tem um pequeno bloco de dados e, no fim, todos obtêm a concatenação de todos os blocos. Produz o mesmo resultado completo em todos os processos.                                                                                                                 |\n",
    "| **ex7a_audio_file_per_rank_por_genero.py** | **Espacial (independente / file-per-rank)** | **Baixa comunicação (`bcast` + `gather`)**            | **Paralelismo por tarefas independentes** | Cada processo processa um conjunto diferente de ficheiros áudio, calculando métricas locais (RMS). Apenas o *root* agrega os resultados finais. Exemplo de paralelismo “embaraçosamente paralelo”, típico em análises massivas de ficheiros.                                   |\n",
    "| **ex7b_imagem_blur3x3_halos.py**           | **Espacial (vizinhança)**                   | **Ponto-a-ponto (`Sendrecv`) + Coletiva (`Gatherv`)** | **Halo exchange (estêncil 3×3)**          | Cada processo processa um bloco contíguo da imagem e troca linhas de fronteira com os vizinhos superior e inferior. O *halo exchange* garante continuidade e elimina descontinuidades nas fronteiras internas. Exemplo completo de paralelismo espacial com dependência local. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d90435-3155-4e97-bdea-9316ac5d25f7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
