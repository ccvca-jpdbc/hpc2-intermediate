{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5619f2d1-0d06-4a75-b592-f247af6f93da",
   "metadata": {},
   "source": [
    "# 1. CONCEITOS FUNDAMENTAIS\n",
    "\n",
    "Em programação paralela, o objetivo é dividir o trabalho de modo a que várias unidades de processamento (processos ou cores) executem partes do problema em simultâneo.\n",
    "\n",
    "Essa divisão pode ocorrer de duas formas principais:\n",
    "\n",
    "**Distribuição espacial (ou decomposição de dados)**\n",
    "\n",
    "Cada processo trata uma parte diferente dos dados, executando o mesmo algoritmo sobre subconjuntos distintos.\n",
    "\n",
    "> Paradigma dominante em HPC (High Performance Computing).\n",
    "\n",
    "> Permite escalar problemas muito grandes (imagens, matrizes, simulações).\n",
    "\n",
    "> Base das operações Scatter, Gather, Allreduce e Gatherv do MPI.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "Uma matriz 1000×1000 pode ser dividida em blocos de 250×250.\n",
    "\n",
    "Cada processo calcula o seu bloco e, no fim, os resultados são reunidos.\n",
    "\n",
    "**Distribuição temporal (ou paralelismo de tarefas)**\n",
    "\n",
    "Divide-se o trabalho em fases sucessivas de uma mesma tarefa.\n",
    "\n",
    "Cada processo executa uma fase diferente, e os resultados fluem em cadeia — conceito conhecido como pipeline.\n",
    "\n",
    "> Usado em streaming, processamento de áudio/vídeo em tempo real ou simulações com passos de tempo.\n",
    "\n",
    "> O trabalho de cada processo depende do anterior (comunicação ponto-a-ponto).\n",
    "\n",
    "Exemplo:\n",
    "\n",
    " - Processo 0 lê dados de um sensor.\n",
    "\n",
    " - Processo 1 processa esses dados.\n",
    "\n",
    " - Processo 2 grava resultados no disco.\n",
    " \n",
    "Enquanto o processo 1 está a processar, o 0 já pode ler o próximo bloco.\n",
    "\n",
    "As comunicações não bloqueantes (Isend, Irecv) permitem fluxo contínuo (overlap entre leitura, cálculo e escrita).Um problema pode ser dividido segundo duas dimensões principais: espacial (dados) e temporal (tarefas).\n",
    "\n",
    "# 2. MODELOS DE PARALELISMO\n",
    "\n",
    "| Modelo | Tipo | Características | Exemplos |\n",
    "|:--------|:------|:-----------------|:----------|\n",
    "|Data Parallelism |Espacial |Mesma operação em subconjuntos de dados |processamento de imagem, áudio, simulação de partículas|\n",
    "|Task Parallelism|Temporal|Tarefas diferentes sobre o mesmo ou diferentes dados|pipeline, workflow científico|\n",
    "|Pipeline Parallelism|Temporal (sequencial em etapas)|Saída de uma tarefa é entrada da seguinte|processamento de frames, deep learning inference|\n",
    "|Hybrid|Combina ambos|Cada nó executa várias tarefas sobre uma subparte dos dados|simulações complexas, IA distribuída|\n",
    "\n",
    "# 3. DECOMPOSIÇÃO DE PROBLEMAS\n",
    "\n",
    "Um problema pode ser dividido segundo duas dimensões principais: espacial (dados) e temporal (tarefas).\n",
    "\n",
    "**a) Decomposição Espacial (de dados)**\n",
    "\n",
    "> **Divisão geométrica:** domínio físico ou matemático (grelha, matriz, volume 3D).\n",
    "\n",
    "Exemplo: numa simulação 2D, cada processo calcula uma submatriz.\n",
    "   \n",
    "> **Divisão lógica:** conjuntos independentes (ficheiros, blocos de áudio, registos).\n",
    "\n",
    "Exemplo: cada processo processa um ficheiro .wav diferente.\n",
    "   \n",
    "Em HPC, este tipo de decomposição é o mais comum — cada core recebe um subconjunto de dados, processa localmente e comunica com os outros via MPI.\n",
    "\n",
    "Funções relevantes do MPI:\n",
    "\n",
    " - Scatter / Scatterv → distribuição dos dados;\n",
    "\n",
    " - Gather / Gatherv → recolha dos resultados;\n",
    "\n",
    " - Allreduce → combinação de valores (somatório, média, etc.).\n",
    "   \n",
    "**b) Decomposição Temporal (de tarefas)**\n",
    "\n",
    "Divide o trabalho em etapas sequenciais, cada uma realizada por um processo distinto.\n",
    "É uma forma de task parallelism.\n",
    "\n",
    " - Cada processo executa uma fase específica;\n",
    "\n",
    " - As fases comunicam entre si em série, normalmente via Send / Recv ou versões assíncronas Isend / Irecv;\n",
    "\n",
    " - Permite *overlap* temporal — enquanto um processo processa, outro já prepara a próxima entrada.\n",
    "\n",
    "Usos típicos:\n",
    "\n",
    " - Processamento em streaming (áudio, vídeo, sensores);\n",
    "\n",
    " - Simulações dependentes do tempo;\n",
    "\n",
    " - Pipelines de inferência em modelos de IA.\n",
    "    \n",
    "*MPI aplica-se aqui: Isend, Irecv (não bloqueantes) permitem fluxo contínuo.*\n",
    "\n",
    "\n",
    "# 4. RESUMO\n",
    "\n",
    "| Tipo de decomposição   | Comunicação entre processos             | Objetivo                              |\n",
    "| ---------------------- | --------------------------------------- | ------------------------------------- |\n",
    "| **Espacial (dados)**   | Distribuição e recolha (Scatter/Gather) | Processar subconjuntos em paralelo    |\n",
    "| **Temporal (tarefas)** | Fluxo em série (Send/Recv)              | Sobrepor fases diferentes da execução |\n",
    "\n",
    "# 5. COMUNICAÇÃO E MODELOS DE PARALELISMO\n",
    "\n",
    "Os dois grandes modelos de paralelismo — espacial (de dados) e temporal (de tarefas) — concretizam-se, em MPI, através de diferentes tipos de comunicação entre processos.\n",
    "A forma como os processos trocam informação define a eficiência e a escalabilidade da aplicação.\n",
    "\n",
    "### 5.1 Comunicações ponto-a-ponto e coletivas\n",
    "\n",
    "**Comunicações ponto-a-ponto (point-to-point)**\n",
    "\n",
    "> São usadas quando os processos trocam dados diretamente entre si, de forma explícita e controlada.\n",
    "Estão associadas ao paralelismo temporal e a pipelines de tarefas, onde a sequência de operações importa.\n",
    "Exemplo típico: Send, Recv, Isend, Irecv.\n",
    "\n",
    "Aplicações:\n",
    "\n",
    " - Fluxos encadeados (pipelines);\n",
    "\n",
    " - Processamento em tempo real (áudio, sensores, vídeo);\n",
    "\n",
    " - Simulações dependentes do tempo, com dependências entre passos.\n",
    " \n",
    "**Comunicações coletivas (collective)**\n",
    "\n",
    "> Envolvem todo o grupo de processos (COMM_WORLD ou sub-comunicadores) e distribuem ou reúnem dados de forma global.\n",
    "São típicas do paralelismo espacial, onde os dados estão divididos e cada processo contribui com uma parte.\n",
    "Exemplo típico: Scatter, Gather, Allreduce, Bcast.\n",
    "\n",
    "Aplicações:\n",
    "\n",
    " - Processamento de grandes matrizes ou vetores;\n",
    "\n",
    " - Simulações físicas distribuídas em grelhas;\n",
    "\n",
    " - Redução de resultados (somas, médias, máximos).\n",
    " \n",
    "**Em resumo:**\n",
    "\n",
    " - Espacial → comunicação coletiva (dados partilhados globalmente).\n",
    "\n",
    " - Temporal → comunicação ponto-a-ponto (dados encadeados entre tarefas).\n",
    " \n",
    "**Nota sobre deadlock**\n",
    "\n",
    "> Um deadlock (ou impasse) ocorre quando dois ou mais processos ficam bloqueados à espera uns dos outros, impedindo o programa de prosseguir.\n",
    "Em MPI isto acontece, por exemplo, se dois processos chamarem Send em simultâneo sem que nenhum tenha executado o Recv correspondente — ambos aguardam indefinidamente.\n",
    ">\n",
    "> Para evitar este bloqueio:\n",
    ">\n",
    "> - alterna a ordem das chamadas (Send num lado, Recv no outro);\n",
    ">\n",
    "> - ou utiliza Sendrecv, que envia e recebe numa única operação;\n",
    ">\n",
    "> - ou recorre a operações não bloqueantes (Isend, Irecv) seguidas de Wait.\n",
    "\n",
    "Estas estratégias garantem que a comunicação flui sem esperas circulares.\n",
    "\n",
    "\n",
    " \n",
    "### 5.2 Comunicações bloqueantes e não bloqueantes\n",
    "\n",
    "A eficiência do paralelismo depende de como os processos esperam (ou não) pela comunicação:\n",
    "\n",
    " - Bloqueantes (Send, Recv, Bcast, Gather, etc.). O processo espera que a transferência termine antes de continuar. São mais simples e seguras, adequadas a modelos espaciais com sincronização forte — por exemplo, quando todos terminam uma etapa antes da próxima.\n",
    "\n",
    " - Não bloqueantes (Isend, Irecv, Iallreduce, etc.). A comunicação é iniciada, mas o processo pode continuar a computação em paralelo. Usadas em modelos temporais (pipelines ou fluxos contínuos), onde é desejável que leitura, cálculo e escrita ocorram em simultâneo. Permitem overlap entre comunicação e cálculo.\n",
    " \n",
    "### 5.3 Overlapping (computação + comunicação)\n",
    "\n",
    "O overlapping surge naturalmente no paralelismo temporal, quando cada processo realiza simultaneamente partes diferentes da execução.\n",
    "\n",
    " - Exemplo: enquanto um processo está a enviar dados do passo t, outro já processa o passo t+1.\n",
    "\n",
    " - Em MPI, obtém-se *overlap* com operações não bloqueantes (Isend, Irecv) e sincronizações seletivas (Wait, Test).\n",
    "\n",
    " - Nos modelos espaciais, o *overlap* é menos frequente, mas pode ser explorado para trocar fronteiras de domínios enquanto se calcula o interior (método usado em simulações numéricas).\n",
    "\n",
    "O objetivo é reduzir o tempo ocioso dos processos, evitando esperas desnecessárias entre fases de comunicação e cálculo.\n",
    "\n",
    "### 5.4 Comunicação com arrays vs objetos Python\n",
    "\n",
    "A forma como os dados são representados influencia o desempenho:\n",
    "\n",
    " - Modelos espaciais lidam com grandes volumes de dados numéricos (matrizes, vetores). Nesses casos, deve-se usar arrays NumPy ou outros objetos que exponham buffers de memória contíguos, para que o MPI transfira os dados diretamente, sem pickle.\n",
    " \n",
    ">Exemplos: comm.Scatter(array, ...), comm.Gather(array, ...).\n",
    "\n",
    " - Modelos temporais frequentemente lidam com objetos heterogéneos ou mensagens pequenas (strings, estados, pacotes). Aí é mais prático usar comm.send e comm.recv, que funcionam com qualquer objeto Python (serializado internamente).\n",
    "\n",
    ">Exemplo: comm.send(msg, dest=1) / comm.recv(source=0).\n",
    "\n",
    "Regra prática:\n",
    "\n",
    " - Paralelismo espacial → arrays NumPy (eficiência máxima).\n",
    "\n",
    " - Paralelismo temporal → objetos Python (flexibilidade).\n",
    " \n",
    "### 5.5 Síntese das relações entre conceitos e tipos de paralelismo\n",
    "\n",
    "A escolha entre paralelismo espacial e temporal define o tipo de comunicação usada, a forma de sincronização e até o formato dos dados trocados.\n",
    "Abaixo apresentam-se os conceitos e mecanismos típicos de cada modelo.\n",
    "\n",
    "### Paralelismo Espacial (Decomposição de Dados)\n",
    "\n",
    "| Conceito                    | Tipo de Comunicação | Natureza       | Objetivo                                                       | Funções MPI Típicas   | Estrutura de Dados |\n",
    "| --------------------------- | ------------------- | -------------- | -------------------------------------------------------------- | --------------------- | ------------------ |\n",
    "| **Distribuição de dados**   | **Coletiva**        | **Bloqueante** | Dividir dados globais entre processos                          | `Scatter`, `Scatterv` | `numpy.ndarray`    |\n",
    "| **Recolha de resultados**   | **Coletiva**        | **Bloqueante** | Reunir resultados parciais                                     | `Gather`, `Gatherv`   | `numpy.ndarray`    |\n",
    "| **Redução global**          | **Coletiva**        | **Bloqueante** | Combinar valores (soma, média, etc.)                           | `Reduce`, `Allreduce` | `numpy.ndarray`    |\n",
    "| **Sincronização de etapas** | **Coletiva**        | **Bloqueante** | Garantir que todos os processos terminam antes da próxima fase | `Barrier`             | —                  |\n",
    "\n",
    "Características principais:\n",
    "\n",
    " - Todos os processos executam o mesmo algoritmo sobre subconjuntos distintos de dados.\n",
    "\n",
    " - Requer sincronização global em cada iteração.\n",
    "\n",
    " - Comunicações são bloqueantes por natureza.\n",
    "\n",
    " - O desempenho depende da distribuição equilibrada dos dados.\n",
    " \n",
    "### Paralelismo Temporal (Decomposição de Tarefas)\n",
    "\n",
    "| Conceito                       | Tipo de Comunicação | Natureza                          | Objetivo                                   | Funções MPI Típicas          | Estrutura de Dados                       |\n",
    "| ------------------------------ | ------------------- | --------------------------------- | ------------------------------------------ | ---------------------------- | ---------------------------------------- |\n",
    "| **Encadeamento de tarefas**    | **Ponto-a-ponto**   | **Não bloqueante**                | Passar resultados entre etapas do pipeline | `Isend`, `Irecv`             | Objetos Python (mensagens pequenas)      |\n",
    "| **Fluxo contínuo (streaming)** | **Ponto-a-ponto**   | **Não bloqueante**                | Sobrepor leitura, cálculo e escrita        | `Isend`, `Irecv`, `Wait`     | Buffers ou blocos de dados               |\n",
    "| **Comunicação sequencial**     | **Ponto-a-ponto**   | **Bloqueante** (em casos simples) | Transmissão direta sem sobreposição        | `Send`, `Recv`               | Objetos simples (texto, estado, comando) |\n",
    "| **Coordenação entre fases**    | **Ponto-a-ponto**   | **Assíncrona**                    | Sincronizar o pipeline sem paragens totais | `Test`, `Waitany`, `Barrier` | —                                        |\n",
    "\n",
    "Características principais:\n",
    "\n",
    " - Cada processo executa uma fase distinta do processamento.\n",
    "\n",
    " - As fases estão encadeadas — a saída de uma é a entrada da seguinte.\n",
    "\n",
    " - Preferem-se comunicações não bloqueantes para permitir overlap (comunicação + cálculo).\n",
    "\n",
    " - Requer controlo de fluxo para evitar saturação ou bloqueios entre etapas.\n",
    " \n",
    "### Comparação geral\n",
    "\n",
    "| Dimensão     | Tipo de paralelismo | Comunicação dominante | Bloqueio       | Persistência / Fluxo | Exemplo típico                         |\n",
    "| ------------ | ------------------- | --------------------- | -------------- | -------------------- | -------------------------------------- |\n",
    "| **Espacial** | De dados            | Coletiva              | Bloqueante     | Etapas sincronizadas | Processamento de matriz / simulação 2D |\n",
    "| **Temporal** | De tarefas          | Ponto-a-ponto         | Não bloqueante | Fluxo contínuo       | Pipeline de áudio ou vídeo             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71649c9b-04ee-463a-8dde-b87de32147c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/F202500003HPCVLABUTAD/ccvca/notebooks/a_exemplos_mpi\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dc51966-6496-4193-ac9e-d9aaa73da670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 581079\n"
     ]
    }
   ],
   "source": [
    "!sbatch job_espacial.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea558511-7147-4df7-a31c-3ad04508962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sacctmgr show user $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbc5a17-c70a-4fda-9ed7-2478dc1f286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mAccount                    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUsed (h)\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLimit (h)\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mUsed (%)\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩\n",
      "│ f202400002voucherdeucaliona │      437 │     50000 │ \u001b[32m    0.87\u001b[0m │\n",
      "│ f202400002voucherdeucalionx │    95701 │    100000 │ \u001b[33m   95.70\u001b[0m │\n",
      "│ f202500003hpcvlabutada      │      282 │     50000 │ \u001b[32m    0.57\u001b[0m │\n",
      "│ f202500003hpcvlabutadg      │      277 │      1000 │ \u001b[32m   27.75\u001b[0m │\n",
      "│ f202500003hpcvlabutadx      │    17122 │     50000 │ \u001b[32m   34.24\u001b[0m │\n",
      "└─────────────────────────────┴──────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "!billing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdb9208c-a2c9-4d35-8e4e-fe5c4d17126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:            x86_64\n",
      "  CPU op-mode(s):        32-bit, 64-bit\n",
      "  Address sizes:         43 bits physical, 48 bits virtual\n",
      "  Byte Order:            Little Endian\n",
      "CPU(s):                  256\n",
      "  On-line CPU(s) list:   0-255\n",
      "Vendor ID:               AuthenticAMD\n",
      "  Model name:            AMD EPYC 7742 64-Core Processor\n",
      "    CPU family:          23\n",
      "    Model:               49\n",
      "    Thread(s) per core:  2\n",
      "    Core(s) per socket:  64\n",
      "    Socket(s):           2\n",
      "    Stepping:            0\n",
      "    Frequency boost:     enabled\n",
      "    CPU(s) scaling MHz:  88%\n",
      "    CPU max MHz:         2250.0000\n",
      "    CPU min MHz:         1500.0000\n",
      "    BogoMIPS:            4500.04\n",
      "    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mc\n",
      "                         a cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall n\n",
      "                         x mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_go\n",
      "                         od nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pc\n",
      "                         lmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic mov\n",
      "                         be popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy \n",
      "                         svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefe\n",
      "                         tch osvw ibs skinit wdt tce topoext perfctr_core perfct\n",
      "                         r_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_psta\n",
      "                         te ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 \n",
      "                         smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha\n",
      "                         _ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_ll\n",
      "                         c cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr \n",
      "                         wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmc\n",
      "                         b_clean flushbyasid decodeassists pausefilter pfthresho\n",
      "                         ld avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid ove\n",
      "                         rflow_recov succor smca sme sev sev_es\n",
      "Virtualization features: \n",
      "  Virtualization:        AMD-V\n",
      "Caches (sum of all):     \n",
      "  L1d:                   4 MiB (128 instances)\n",
      "  L1i:                   4 MiB (128 instances)\n",
      "  L2:                    64 MiB (128 instances)\n",
      "  L3:                    512 MiB (32 instances)\n",
      "NUMA:                    \n",
      "  NUMA node(s):          2\n",
      "  NUMA node0 CPU(s):     0-63,128-191\n",
      "  NUMA node1 CPU(s):     64-127,192-255\n",
      "Vulnerabilities:         \n",
      "  Itlb multihit:         Not affected\n",
      "  L1tf:                  Not affected\n",
      "  Mds:                   Not affected\n",
      "  Meltdown:              Not affected\n",
      "  Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl\n",
      "                          and seccomp\n",
      "  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer\n",
      "                          sanitization\n",
      "  Spectre v2:            Mitigation; Full AMD retpoline, IBPB conditional, IBRS_\n",
      "                         FW, STIBP conditional, RSB filling\n",
      "  Srbds:                 Not affected\n",
      "  Tsx async abort:       Not affected\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e4777e3-5321-4514-9758-48ab44babcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "!nproc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
